{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn_version = sklearn.__version__\n",
    "print(sklearn_version)\n",
    "#needs to be 0.24.2\n",
    "\n",
    "import gensim\n",
    "gensim.__version__\n",
    "#3.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.deprecated.doc2vec import LabeledSentence\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from string import digits\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random \n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, plot_precision_recall_curve, auc, average_precision_score,classification_report, confusion_matrix, accuracy_score, average_precision_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, RepeatedStratifiedKFold, train_test_split,KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from modAL.uncertainty import entropy_sampling\n",
    "from modAL.density import information_density\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/carlyknight/Dropbox/PROJECTS/Corporate Annual Reports/Replication Folder RR/dictionary_verification/training_paragraphlevel_8-30-21.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['long_filename', 'doc_id', 'year', 'text', 'coop_count', 'coord_count',\n",
       "       'fulltext_count', 'coord_score', 'coop_score', 'Coordination',\n",
       "       'Cooperation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing (remove punctuation, numbers, lowercase)/ remove stopwords\n",
    "punctuation_dictionary = {s:None for s in list(string.punctuation)}\n",
    "\n",
    "punctuation_translator = str.maketrans(punctuation_dictionary)\n",
    "\n",
    "def text_cleaner(text, punctuation_translator):\n",
    "    text=str(text)\n",
    "    text = text.replace('c(\"', '')\n",
    "    text = str(text).translate(punctuation_translator)\n",
    "    text = text.lower()\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    text= remove_stopwords(text)\n",
    "    return(text)\n",
    "\n",
    "data[\"clean_text\"] = data[\"text\"].apply(lambda x: text_cleaner(x, punctuation_translator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0      atyred checchxcxac cochairman gary l wilson co...\n",
       "1      management took actions year reduce costs cons...\n",
       "2      finest fsolntcs gii iced service icljxcxac sei...\n",
       "3      union_camp aggressively pursued forest managem...\n",
       "4      stockholder rights plan pursuant stockholder r...\n",
       "                             ...                        \n",
       "995    community relations highlightsat spokane washi...\n",
       "996    past_years time unprecedented worldwide growth...\n",
       "997    fenix union_pacific long forefront developing ...\n",
       "998    note pension retirement_plans company_subsidia...\n",
       "999    safe harbor statement nature companys operatio...\n",
       "Name: phrased_text, Length: 1000, dtype: object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find phrases\n",
    "phrases1 = Phrases(map(lambda x: x.split(), data[\"clean_text\"].tolist())) #bigram\n",
    "phrases2 = Phrases(phrases1[map(lambda x: x.split(), data[\"clean_text\"].tolist())]) #trigram\n",
    "data[\"phrased_text\"] = data[\"clean_text\"].apply(lambda x: \" \".join(phrases2[phrases1[x.split()]]))\n",
    "\n",
    "#add row_id\n",
    "data['row.id'] = np.arange(len(data))\n",
    "data[\"phrased_text\"].head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine cooperation & coordination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop data that has both coordination and cooperation\n",
    "data_multi = data[~((data[\"Cooperation\"] == 1) & (data[\"Coordination\"] == 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlyknight/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/carlyknight/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/Users/carlyknight/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "#create an multinomial outcome\n",
    "data_multi['Outcome']=0\n",
    "data_multi.loc[data_multi['Cooperation'] ==1, 'Outcome'] = 1\n",
    "data_multi.loc[data_multi['Coordination'] ==1, 'Outcome'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    588\n",
       "1    201\n",
       "2    190\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_multi['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "vectorizer = CountVectorizer(min_df=5)\n",
    "X = vectorizer.fit_transform(data_multi[\"phrased_text\"]).toarray()\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X_tf = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "y = np.array(data_multi['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9589dcb3e4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# report the model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Accuracy: %.3f (%.3f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver = 'lbfgs')\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X_train, y_train, scoring='recall', cv=cv, n_jobs=-1)\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'none', 'random_state': 0, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "#https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "\n",
    "#training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.3)\n",
    "\n",
    "model = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', solver='newton-cg').fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "#print the tunable parameters (They were not tuned in this example, everything kept as default)\n",
    "params = model.get_params()\n",
    "print(params)\n",
    "\n",
    "confusion_matrix(y_test, preds)\n",
    "#transform confusion matrix into array\n",
    "confmtrx = np.array(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_none</th>\n",
       "      <th>predicted_cooperation</th>\n",
       "      <th>predicted_coordination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cooperation</th>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coordination</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_none  predicted_cooperation  predicted_coordination\n",
       "None                     149                      8                      20\n",
       "Cooperation               29                     25                       6\n",
       "Coordination              27                      6                      24"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create DataFrame from confmtrx array \n",
    "#rows for test:\n",
    "#columns for preds: male, predicted_female, predicted_infant as column\n",
    "\n",
    "pd.DataFrame(confmtrx, index=['None','Cooperation', 'Coordination'],\n",
    "columns=['predicted_none', 'predicted_cooperation', 'predicted_coordination'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78       177\n",
      "           1       0.64      0.42      0.51        60\n",
      "           2       0.48      0.42      0.45        57\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.62      0.56      0.58       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create classification report\n",
    "class_report=classification_report(y_test, preds)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic: Cooperation\n",
    "\n",
    "#https://medium.com/analytics-vidhya/applying-text-classification-using-logistic-regression-a-comparison-between-bow-and-tf-idf-1f1ed1b83640\n",
    "\n",
    "#best preprocessing seems to be: remove digits, remove punctuation, do not lowercase,do not remove stopwords\n",
    "\n",
    "#https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "vectorizer = CountVectorizer(min_df=5)\n",
    "X = vectorizer.fit_transform(data[\"phrased_text\"]).toarray()\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X_tf = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "y = np.array(data['Cooperation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.666746 using {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.584601 (0.150546) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.584601 (0.150546) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.585342 (0.151546) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.666746 (0.200054) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.666746 (0.200054) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.666746 (0.200054) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.333333 (0.471405) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.333333 (0.471405) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.333333 (0.471405) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.05, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.05, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.05, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "#https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "\n",
    "#training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.3)\n",
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.05, 0.01]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search_coop = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='precision',error_score=0)\n",
    "grid_result_coop = grid_search_coop.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_coop.best_score_, grid_result_coop.best_params_))\n",
    "means = grid_result_coop.cv_results_['mean_test_score']\n",
    "stds = grid_result_coop.cv_results_['std_test_score']\n",
    "params = grid_result_coop.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8066666666666666\n",
      "Precision:  0.9047619047619048\n",
      "Recall:  0.25333333333333335\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_result_coop.best_estimator_.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/carlyknight/Dropbox/PROJECTS/Corporate Annual Reports/Replication Folder RR/coord_coop/cooperation_logistic.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save\n",
    "import joblib\n",
    "joblib.dump(grid_search_coop.best_estimator_, \"/Users/carlyknight/Dropbox/PROJECTS/Corporate Annual Reports/Replication Folder RR/coord_coop/cooperation_logistic.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic: Coordination\n",
    "\n",
    "#https://medium.com/analytics-vidhya/applying-text-classification-using-logistic-regression-a-comparison-between-bow-and-tf-idf-1f1ed1b83640\n",
    "\n",
    "#best preprocessing seems to be: remove digits, remove punctuation, do not lowercase,do not remove stopwords\n",
    "\n",
    "#https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data['Coordination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.616987 using {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.543870 (0.154505) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.543870 (0.154505) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.543870 (0.154505) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.616987 (0.198438) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.616987 (0.198438) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.610717 (0.190944) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.100000 (0.300000) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.100000 (0.300000) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.100000 (0.300000) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.05, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.05, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.05, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "#https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "\n",
    "#training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.3)\n",
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.05, 0.01]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search_coord = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='precision',error_score=0)\n",
    "grid_result_coord = grid_search_coord.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_coord.best_score_, grid_result_coord.best_params_))\n",
    "means = grid_result_coord.cv_results_['mean_test_score']\n",
    "stds = grid_result_coord.cv_results_['std_test_score']\n",
    "params = grid_result_coord.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8\n",
      "Precision:  0.6086956521739131\n",
      "Recall:  0.2153846153846154\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search_coord.best_estimator_.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open all data\n",
    "files = \"/Users/carlyknight/Documents/Data/Annual Report/report_paragraphs/wagefirmtexts/wagefirmtexts_afterML/by_para/\"\n",
    "wagefiles = os.listdir(files)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of paragraphs\n",
    "paragraph_list = []\n",
    "\n",
    "for file in wagefiles:\n",
    "    #open text\n",
    "    with open(os.path.join(files, str(file)),  'rb') as f:\n",
    "        text = f.readlines()\n",
    "        paragraph_list.append([file, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88521"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraph_list)\n",
    "#paragraph should be around 88,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into pandas\n",
    "df = pd.DataFrame.from_records(paragraph_list)\n",
    "df.columns = ['doc.id', 'para']\n",
    "\n",
    "#add row_id\n",
    "df['row.id'] = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88521, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing (remove punctuation, numbers, lowercase)/ remove stopwords\n",
    "punctuation_dictionary = {s:None for s in list(string.punctuation)}\n",
    "\n",
    "punctuation_translator = str.maketrans(punctuation_dictionary)\n",
    "\n",
    "\n",
    "def text_cleaner(text, punctuation_translator):\n",
    "    text=str(text)\n",
    "    text = text.replace('c(\"', '')\n",
    "    text = str(text).translate(punctuation_translator)\n",
    "    text = text.lower()\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    text= remove_stopwords(text)\n",
    "    return(text)\n",
    "\n",
    "df[\"clean_para\"] = df[\"para\"].apply(lambda x: text_cleaner(x, punctuation_translator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrases\n",
    "phrases1 = Phrases(map(lambda x: x.split(), df[\"clean_para\"].tolist())) #bigram\n",
    "phrases2 = Phrases(phrases1[map(lambda x: x.split(), df[\"clean_para\"].tolist())]) #trigram\n",
    "df[\"clean_phrase\"] = df[\"clean_para\"].apply(lambda x: \" \".join(phrases2[phrases1[x.split()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "X = vectorizer.transform(df[\"clean_para\"]).toarray()\n",
    "X_tf = tfidfconverter.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cooperation predictions\n",
    "cooperation = grid_search_coop.best_estimator_.predict(X_tf)\n",
    "\n",
    "#Coordination predictions\n",
    "coordination = grid_search_coord.best_estimator_.predict(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put predictions in df\n",
    "df['coop_hat'] = cooperation\n",
    "df['coord_hat'] = coordination\n",
    "\n",
    "df.to_csv(\"/Users/carlyknight/Dropbox/PROJECTS/Corporate Annual Reports/Replication Folder RR/coord_coop/coord_coop_scores_afterml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7525"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['coop_hat'])\n",
    "#7,525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7631"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['coord_hat'])\n",
    "#7,631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
